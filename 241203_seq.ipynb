{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92b04db-2507-4b29-9a78-ded45ecf50ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator\n",
    "import json\n",
    "from torch.optim import SGD\n",
    "\n",
    "def exact_match_accuracy(generated_completions, target_completions, prompts):\n",
    "    correct_count = 0 \n",
    "    for gen, target, prompt in zip(generated_completions, target_completions, prompts):\n",
    "        # Remove the prompt from the generated completion\n",
    "        generated_part = gen[len(prompt):]  # Take everything after the prompt\n",
    "\n",
    "        # Check if the generated part starts with the target completion (case-insensitive)\n",
    "        if generated_part.strip().lower().startswith(target.strip().lower()):\n",
    "            correct_count += 1\n",
    "    \n",
    "    # Calculate accuracy as the percentage of correct matches\n",
    "    accuracy = correct_count / len(generated_completions) if len(generated_completions) > 0 else 0.0\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def evaluate(model, tokenizer, test_data):\n",
    "    model.eval()\n",
    "    test_prompts = [item['prompt'] for item in test_data]\n",
    "    test_completions = [item['completion'] for item in test_data]\n",
    "\n",
    "    generated_completions = []\n",
    "    \n",
    "    for prompt in test_prompts:\n",
    "        # Tokenize each prompt separately without padding\n",
    "        inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
    "\n",
    "        # Generate completion one by one (no padding)\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(\n",
    "                **inputs,\n",
    "                max_length=64,\n",
    "            )\n",
    "\n",
    "        # Decode the generated completion\n",
    "        generated_completions.append(tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "\n",
    "    # Evaluate the accuracy based on whether the generated part starts with the target completion\n",
    "    accuracy = exact_match_accuracy(generated_completions, test_completions, test_prompts)\n",
    "\n",
    "    return generated_completions, accuracy\n",
    "\n",
    "########################### main code \n",
    "\n",
    "with open(\"d2p_each_dataset.json\", 'r') as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model_name = \"meta-llama/Llama-3.2-1B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Open the .jsonl file in append mode to store results\n",
    "with open(\"evaluation_results.jsonl\", 'a') as jsonl_file:\n",
    "\n",
    "    test_datasets = {}\n",
    "\n",
    "    for idx, individual_data in enumerate(dataset):\n",
    "        print(f\"Training on dataset {idx + 1}\")\n",
    "        \n",
    "        # Prepare the train and test data\n",
    "        train_data = individual_data['train']\n",
    "        test_data = individual_data['test']\n",
    "        test_datasets[idx] = test_data\n",
    "        \n",
    "        # Convert to Hugging Face Dataset (directly use 'text' field)\n",
    "        train_dataset = Dataset.from_dict({\n",
    "            'text': [item['prompt'] + item['completion'] for item in train_data]\n",
    "        })\n",
    "        print(train_dataset)\n",
    "        print(train_dataset[0])\n",
    "        \n",
    "        training_args = SFTConfig(\n",
    "            output_dir=\"/tmp\",   \n",
    "            num_train_epochs=3,                      # Number of epochs\n",
    "            per_device_train_batch_size=30,           # Batch size per device \n",
    "            max_seq_length=128,\n",
    "            logging_steps=100,\n",
    "        )\n",
    "\n",
    "        # Initialize SFTTrainer with the model, dataset, and config\n",
    "        # Create SGD optimizer\n",
    "        optimizer = SGD(model.parameters(), lr=5e-2)  # Use a learning rate of 0.005\n",
    "\n",
    "        # Initialize SFTTrainer with the model, dataset, config, optimizer, and scheduler\n",
    "        trainer = SFTTrainer(\n",
    "            model=model,\n",
    "            train_dataset=train_dataset,\n",
    "            tokenizer=tokenizer,\n",
    "            args=training_args,  # Pass the training config\n",
    "            optimizers=(optimizer,None)  # Pass only the optimizer (no scheduler for now)\n",
    "        )\n",
    "\n",
    "        # Train the model using the SFTTrainer\n",
    "        trainer.train()\n",
    "\n",
    "        #### Evaluate performance on all test datasets after training on this one\n",
    "        for test_data_idx, test_data in test_datasets.items():\n",
    "            generated_completions, accuracy = evaluate(model, tokenizer, test_data)\n",
    "\n",
    "            # Prepare the result to be written as a JSON object\n",
    "            result = {\n",
    "                'train_data_idx': idx,\n",
    "                'test_data_idx': test_data_idx,\n",
    "                'accuracy': accuracy\n",
    "            }\n",
    "            \n",
    "            # Write the result as a new line in the .jsonl file\n",
    "            jsonl_file.write(json.dumps(result) + '\\n')\n",
    "\n",
    "            # Optionally, print the results\n",
    "            print(f\"Evaluating on Test Dataset {test_data_idx + 1} after training on Dataset {idx + 1}\")\n",
    "            print(f\"Exact Match Accuracy: {accuracy * 100:.2f}%\")\n",
    "        \n",
    "        # Clear GPU memory after each dataset\n",
    "        torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8261ce54-5e52-448e-920a-aee9e36b85da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator\n",
    "import json\n",
    "from torch.optim import SGD\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model_name = \"meta-llama/Llama-3.2-1B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186ea23-abe6-40c4-a8a4-538b378470e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda:.conda-fact]",
   "language": "python",
   "name": "conda-env-.conda-fact-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
